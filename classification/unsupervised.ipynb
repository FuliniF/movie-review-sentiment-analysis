{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('../data/train_imdb_reviews.csv')\n",
    "test_df = pd.read_csv('../data/test_imdb_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reviews: 41669\n",
      "Positive reviews: 27295\n",
      "Negative reviews: 14374\n",
      "ratio: 1.8989147071100598\n",
      "-------------------------\n",
      "Positive reviews: 14374\n",
      "Negative reviews: 14374\n",
      "ratio: 1.0\n"
     ]
    }
   ],
   "source": [
    "# This cell is only for experiments of balancing dataset sentiments\n",
    "\n",
    "positive_count = train_df[train_df[\"sentiment\"] == 1].shape[0]\n",
    "negative_count = train_df[train_df[\"sentiment\"] == 0].shape[0]\n",
    "print(\"Total reviews:\", train_df.shape[0])\n",
    "print(\"Positive reviews:\", positive_count)\n",
    "print(\"Negative reviews:\", negative_count)\n",
    "print(\"ratio:\", positive_count/negative_count)\n",
    "\n",
    "print(\"-------------------------\")\n",
    "\n",
    "positive = train_df[train_df[\"sentiment\"] == 1][:negative_count]\n",
    "negative = train_df[train_df[\"sentiment\"] == 0]\n",
    "print(\"Positive reviews:\", positive.shape[0])\n",
    "print(\"Negative reviews:\", negative.shape[0])\n",
    "print(\"ratio:\", positive.shape[0]/negative.shape[0])\n",
    "\n",
    "train_df = pd.concat([positive, negative])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['data_type'] = 'train'\n",
    "test_df['data_type'] = 'test'\n",
    "\n",
    "all_df = pd.concat([train_df, test_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33378\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>score</th>\n",
       "      <th>title</th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>data_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>從前，有個好萊塢</td>\n",
       "      <td>10.0</td>\n",
       "      <td>tarantinos best</td>\n",
       "      <td>never wanted end said loved ending made weep l...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>不可能的任務：致命清算 第一章</td>\n",
       "      <td>7.0</td>\n",
       "      <td>theres nothing else see</td>\n",
       "      <td>first ive got say im huge fan franchise saw mo...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>之前的我們</td>\n",
       "      <td>8.0</td>\n",
       "      <td>irony poor connection talked facetime</td>\n",
       "      <td>past lives first great doomed love story audie...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>從前，有個好萊塢</td>\n",
       "      <td>8.0</td>\n",
       "      <td>tarantinos love letter golden age</td>\n",
       "      <td>upon time hollywood perfect movie awesome one ...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>旺卡</td>\n",
       "      <td>9.0</td>\n",
       "      <td>must see keep tradition alive</td>\n",
       "      <td>enjoyed every bit movie acting especially stor...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             movie  score                                  title  \\\n",
       "0         從前，有個好萊塢   10.0                        tarantinos best   \n",
       "1  不可能的任務：致命清算 第一章    7.0                theres nothing else see   \n",
       "2            之前的我們    8.0  irony poor connection talked facetime   \n",
       "3         從前，有個好萊塢    8.0      tarantinos love letter golden age   \n",
       "4               旺卡    9.0          must see keep tradition alive   \n",
       "\n",
       "                                              review  sentiment data_type  \n",
       "0  never wanted end said loved ending made weep l...          1     train  \n",
       "1  first ive got say im huge fan franchise saw mo...          1     train  \n",
       "2  past lives first great doomed love story audie...          1     train  \n",
       "3  upon time hollywood perfect movie awesome one ...          1     train  \n",
       "4  enjoyed every bit movie acting especially stor...          1     train  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = all_df.reset_index(drop=True)\n",
    "\n",
    "print(len(all_data))\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import strip_tags\n",
    "from nltk import word_tokenize\n",
    "\n",
    "def tokenize(doc):\n",
    "    return simple_preprocess(strip_tags(doc), deacc=True, min_len=2, max_len=15)\n",
    "\n",
    "all_data['tagged_docs'] = all_data.apply(lambda r: TaggedDocument(tokenize(r['review']), [str(r.name)]), axis=1)\n",
    "all_data['doc_key'] = all_data.index.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>score</th>\n",
       "      <th>title</th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>data_type</th>\n",
       "      <th>tagged_docs</th>\n",
       "      <th>doc_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>從前，有個好萊塢</td>\n",
       "      <td>10.0</td>\n",
       "      <td>tarantinos best</td>\n",
       "      <td>never wanted end said loved ending made weep l...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>([never, wanted, end, said, loved, ending, mad...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>不可能的任務：致命清算 第一章</td>\n",
       "      <td>7.0</td>\n",
       "      <td>theres nothing else see</td>\n",
       "      <td>first ive got say im huge fan franchise saw mo...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>([first, ive, got, say, im, huge, fan, franchi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>之前的我們</td>\n",
       "      <td>8.0</td>\n",
       "      <td>irony poor connection talked facetime</td>\n",
       "      <td>past lives first great doomed love story audie...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>([past, lives, first, great, doomed, love, sto...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>從前，有個好萊塢</td>\n",
       "      <td>8.0</td>\n",
       "      <td>tarantinos love letter golden age</td>\n",
       "      <td>upon time hollywood perfect movie awesome one ...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>([upon, time, hollywood, perfect, movie, aweso...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>旺卡</td>\n",
       "      <td>9.0</td>\n",
       "      <td>must see keep tradition alive</td>\n",
       "      <td>enjoyed every bit movie acting especially stor...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>([enjoyed, every, bit, movie, acting, especial...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             movie  score                                  title  \\\n",
       "0         從前，有個好萊塢   10.0                        tarantinos best   \n",
       "1  不可能的任務：致命清算 第一章    7.0                theres nothing else see   \n",
       "2            之前的我們    8.0  irony poor connection talked facetime   \n",
       "3         從前，有個好萊塢    8.0      tarantinos love letter golden age   \n",
       "4               旺卡    9.0          must see keep tradition alive   \n",
       "\n",
       "                                              review  sentiment data_type  \\\n",
       "0  never wanted end said loved ending made weep l...          1     train   \n",
       "1  first ive got say im huge fan franchise saw mo...          1     train   \n",
       "2  past lives first great doomed love story audie...          1     train   \n",
       "3  upon time hollywood perfect movie awesome one ...          1     train   \n",
       "4  enjoyed every bit movie acting especially stor...          1     train   \n",
       "\n",
       "                                         tagged_docs doc_key  \n",
       "0  ([never, wanted, end, said, loved, ending, mad...       0  \n",
       "1  ([first, ive, got, say, im, huge, fan, franchi...       1  \n",
       "2  ([past, lives, first, great, doomed, love, sto...       2  \n",
       "3  ([upon, time, hollywood, perfect, movie, aweso...       3  \n",
       "4  ([enjoyed, every, bit, movie, acting, especial...       4  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to do this unsupervised classification task, I need to define some of the keywords by myself.\\\n",
    "The detailed method and reason to do this can be referred to its original paper: Evaluating Unsupervised Text Classification: Zero-shot and Similarity-based Approaches (https://arxiv.org/abs/2211.16285)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   class_id class_name                                           keywords  \\\n",
      "0         1   positive  [nice, masterpiece, beautiful, excellent, awes...   \n",
      "1         2   negative  [horrible, bad, disgusting, terrible, awful, b...   \n",
      "\n",
      "   num_keywords  \n",
      "0             8  \n",
      "1             8  \n"
     ]
    }
   ],
   "source": [
    "label_df = pd.read_csv('../data/labels.csv')\n",
    "label_df['keywords'] = label_df['keywords'].apply(lambda x: x.split(' '))\n",
    "label_df['num_keywords'] = label_df['keywords'].apply(lambda x: len(x))\n",
    "\n",
    "print(label_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df['class_name'] = label_df['class_name'].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lbl2vec import Lbl2TransformerVec, Lbl2Vec\n",
    "from transformers import AutoModel\n",
    "from tqdm import tqdm\n",
    "from gensim.models import Doc2Vec\n",
    "\n",
    "lblModel = Lbl2Vec(keywords_list=list(label_df['keywords']), tagged_documents=all_data['tagged_docs'][all_data['data_type']=='train'], label_names=list(label_df['class_name']), epochs=10, min_count=20, verbose=True)\n",
    "\n",
    "# baseModel = AutoModel.from_pretrained('princeton-nlp/unsup-simcse-roberta-base').to(device)\n",
    "# lblModel = Lbl2TransformerVec(transformer_model=baseModel, keywords_list=list(label_df['keywords']), documents=all_data[all_data['data_type']=='train']['review'], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-15 00:37:51,748 - Lbl2Vec - INFO - Train document and word embeddings\n",
      "2024-03-15 00:37:51,748 - Lbl2Vec - INFO - Train document and word embeddings\n",
      "2024-03-15 00:37:51,748 - Lbl2Vec - INFO - Train document and word embeddings\n",
      "2024-03-15 00:38:26,655 - Lbl2Vec - INFO - Train label embeddings\n",
      "2024-03-15 00:38:26,655 - Lbl2Vec - INFO - Train label embeddings\n",
      "2024-03-15 00:38:26,655 - Lbl2Vec - INFO - Train label embeddings\n"
     ]
    }
   ],
   "source": [
    "lblModel.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "lblModel.save('models/lbl2vec_balance_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-15 00:38:27,418 - Lbl2Vec - INFO - Get document embeddings from model\n",
      "2024-03-15 00:38:27,418 - Lbl2Vec - INFO - Get document embeddings from model\n",
      "2024-03-15 00:38:27,418 - Lbl2Vec - INFO - Get document embeddings from model\n",
      "2024-03-15 00:38:27,432 - Lbl2Vec - INFO - Calculate document<->label similarities\n",
      "2024-03-15 00:38:27,432 - Lbl2Vec - INFO - Calculate document<->label similarities\n",
      "2024-03-15 00:38:27,432 - Lbl2Vec - INFO - Calculate document<->label similarities\n"
     ]
    }
   ],
   "source": [
    "model_docs_lbl_similarities = lblModel.predict_model_docs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_key</th>\n",
       "      <th>most_similar_label</th>\n",
       "      <th>highest_similarity_score</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.626312</td>\n",
       "      <td>0.626312</td>\n",
       "      <td>0.625776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.317811</td>\n",
       "      <td>0.208327</td>\n",
       "      <td>0.317811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.311061</td>\n",
       "      <td>0.311061</td>\n",
       "      <td>0.236579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.223695</td>\n",
       "      <td>0.223695</td>\n",
       "      <td>0.187032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.466779</td>\n",
       "      <td>0.466779</td>\n",
       "      <td>0.211912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  doc_key most_similar_label  highest_similarity_score  positive  negative\n",
       "0       0           positive                  0.626312  0.626312  0.625776\n",
       "1       1           negative                  0.317811  0.208327  0.317811\n",
       "2       2           positive                  0.311061  0.311061  0.236579\n",
       "3       3           positive                  0.223695  0.223695  0.187032\n",
       "4       4           positive                  0.466779  0.466779  0.211912"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_docs_lbl_similarities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    positive\n",
      "1    negative\n",
      "2    positive\n",
      "3    positive\n",
      "4    positive\n",
      "Name: most_similar_label, dtype: object\n"
     ]
    }
   ],
   "source": [
    "y_train = all_data['sentiment']\n",
    "y_pred = model_docs_lbl_similarities['most_similar_label']\n",
    "\n",
    "print(y_pred[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    0\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: most_similar_label, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] == 'positive':\n",
    "        y_pred[i] = 1\n",
    "    else:\n",
    "        y_pred[i] = 0\n",
    "\n",
    "print(y_pred[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28748 33378\n",
      "11151 8245 6129 3223\n",
      "28748\n"
     ]
    }
   ],
   "source": [
    "tp = 0\n",
    "tn = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "\n",
    "print(len(y_pred), len(y_train))\n",
    "\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] == 1 and y_train.iloc[i] == 1:\n",
    "        tp += 1\n",
    "    elif y_pred[i] == 0 and y_train.iloc[i] == 0:\n",
    "        tn += 1\n",
    "    elif y_pred[i] == 1 and y_train.iloc[i] == 0:\n",
    "        fp += 1\n",
    "    elif y_pred[i] == 0 and y_train.iloc[i] == 1:\n",
    "        fn += 1\n",
    "\n",
    "print(tp, tn, fp, fn)\n",
    "print(tp + tn + fp + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true positives:  11151\n",
      "true negatives:  8245\n",
      "false positives:  6129\n",
      "false negatives:  3223\n",
      "Accuracy:  0.6746904132461389\n",
      "Precision:  0.6453125\n",
      "Recall:  0.775775706136079\n",
      "F1:  0.7045555064130916\n",
      "AUC:  0.6746904132461389\n"
     ]
    }
   ],
   "source": [
    "def auc(tp, fp, tn, fn):\n",
    "    return (tp / (tp + fn) + tn / (tn + fp)) / 2\n",
    "\n",
    "print(\"true positives: \", tp)\n",
    "print(\"true negatives: \", tn)\n",
    "print(\"false positives: \", fp)\n",
    "print(\"false negatives: \", fn)\n",
    "\n",
    "acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(\"Accuracy: \", acc)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1: \", f1)\n",
    "print(\"AUC: \", auc(tp, fp, tn, fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lbl2vec import Lbl2TransformerVec\n",
    "from tqdm import tqdm\n",
    "\n",
    "model = Lbl2TransformerVec.load('lbl2vec_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_df = pd.read_csv('../data/test_imdb_reviews.csv')\n",
    "\n",
    "X_test = test_df['review'].astype(str)\n",
    "y_test = test_df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-15 00:39:03,176 - Lbl2Vec - INFO - Calculate document embeddings\n",
      "2024-03-15 00:39:03,176 - Lbl2Vec - INFO - Calculate document embeddings\n",
      "2024-03-15 00:39:03,176 - Lbl2Vec - INFO - Calculate document embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-15 00:39:06,331 - Lbl2Vec - INFO - Calculate document<->label similarities\n",
      "2024-03-15 00:39:06,331 - Lbl2Vec - INFO - Calculate document<->label similarities\n",
      "2024-03-15 00:39:06,331 - Lbl2Vec - INFO - Calculate document<->label similarities\n"
     ]
    }
   ],
   "source": [
    "new_docs_lbl_similarities = lblModel.predict_new_docs(tagged_docs=all_data['tagged_docs'][all_data['data_type']=='test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_key</th>\n",
       "      <th>most_similar_label</th>\n",
       "      <th>highest_similarity_score</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28748</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.421605</td>\n",
       "      <td>0.421605</td>\n",
       "      <td>0.164033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28749</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.576993</td>\n",
       "      <td>0.576993</td>\n",
       "      <td>0.394001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28750</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.239823</td>\n",
       "      <td>0.239823</td>\n",
       "      <td>0.183607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28751</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.622303</td>\n",
       "      <td>0.622303</td>\n",
       "      <td>0.499031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28752</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.460922</td>\n",
       "      <td>0.460922</td>\n",
       "      <td>0.405098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  doc_key most_similar_label  highest_similarity_score  positive  negative\n",
       "0   28748           positive                  0.421605  0.421605  0.164033\n",
       "1   28749           positive                  0.576993  0.576993  0.394001\n",
       "2   28750           positive                  0.239823  0.239823  0.183607\n",
       "3   28751           positive                  0.622303  0.622303  0.499031\n",
       "4   28752           positive                  0.460922  0.460922  0.405098"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_docs_lbl_similarities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: most_similar_label, dtype: object\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = new_docs_lbl_similarities['most_similar_label']\n",
    "\n",
    "for i in range(len(y_test_pred)):\n",
    "    if y_test_pred[i] == 'positive':\n",
    "        y_test_pred[i] = 1\n",
    "    else:\n",
    "        y_test_pred[i] = 0\n",
    "\n",
    "print(y_test_pred[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true positives:  2447\n",
      "true negatives:  936\n",
      "false positives:  627\n",
      "false negatives:  620\n",
      "Accuracy:  0.7306695464362851\n",
      "Precision:  0.7960312296681847\n",
      "Recall:  0.797848059993479\n",
      "F1:  0.7969386093470119\n",
      "AUC:  0.6983482142577759\n"
     ]
    }
   ],
   "source": [
    "test_tp = 0\n",
    "test_tn = 0\n",
    "test_fp = 0\n",
    "test_fn = 0\n",
    "\n",
    "for i in range(len(y_test_pred)):\n",
    "    if y_test_pred[i] == 1 and y_test.iloc[i] == 1:\n",
    "        test_tp += 1\n",
    "    elif y_test_pred[i] == 0 and y_test.iloc[i] == 0:\n",
    "        test_tn += 1\n",
    "    elif y_test_pred[i] == 1 and y_test.iloc[i] == 0:\n",
    "        test_fp += 1\n",
    "    elif y_test_pred[i] == 0 and y_test.iloc[i] == 1:\n",
    "        test_fn += 1\n",
    "\n",
    "print(\"true positives: \", test_tp)\n",
    "print(\"true negatives: \", test_tn)\n",
    "print(\"false positives: \", test_fp)\n",
    "print(\"false negatives: \", test_fn)\n",
    "\n",
    "test_acc = (test_tp + test_tn) / (test_tp + test_tn + test_fp + test_fn)\n",
    "test_precision = test_tp / (test_tp + test_fp)\n",
    "test_recall = test_tp / (test_tp + test_fn)\n",
    "test_f1 = 2 * (test_precision * test_recall) / (test_precision + test_recall)\n",
    "test_auc = auc(test_tp, test_fp, test_tn, test_fn)\n",
    "\n",
    "print(\"Accuracy: \", test_acc)\n",
    "print(\"Precision: \", test_precision)\n",
    "print(\"Recall: \", test_recall)\n",
    "print(\"F1: \", test_f1)\n",
    "print(\"AUC: \", test_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIcap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
